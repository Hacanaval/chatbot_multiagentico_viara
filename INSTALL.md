# ğŸš€ GuÃ­a de InstalaciÃ³n - VIARA

## ğŸ“‹ Requisitos Previos

### 1. Python 3.10+
```bash
python --version  # Debe ser 3.10 o superior
```

### 2. Instalar Ollama
```bash
# macOS/Linux
curl -fsSL https://ollama.ai/install.sh | sh

# Windows: Descargar desde https://ollama.ai/download
```

### 3. Descargar modelo LLM
```bash
ollama pull phi3:mini
# o alternativamente:
ollama pull llama3:8b
```

## ğŸ“¦ InstalaciÃ³n del Proyecto

### 1. Clonar repositorio
```bash
git clone https://github.com/Hacanaval/chatbot_multiagentico_viara.git
cd chatbot_multiagentico_viara
```

### 2. Crear entorno virtual (recomendado)
```bash
python -m venv venv

# Activar entorno:
# macOS/Linux:
source venv/bin/activate
# Windows:
venv\Scripts\activate
```

### 3. Instalar dependencias
```bash
pip install -r requirements.txt
```

## ğŸ§ª VerificaciÃ³n de InstalaciÃ³n

### Test rÃ¡pido del sistema
```bash
# Verificar backend
python orchestrator_parallel.py

# Verificar frontend
python run_app.py
```

## ğŸš€ Ejecutar VIARA

### OpciÃ³n 1: Script de inicio (Recomendado)
```bash
python run_app.py
```

### OpciÃ³n 2: Streamlit directo
```bash
streamlit run main.py
```

### OpciÃ³n 3: Solo backend (sin UI)
```bash
python orchestrator_parallel.py
```

## ğŸ› ï¸ ConfiguraciÃ³n Personalizada

### Cambiar modelo LLM
Edita `utils/ollama_client.py`:
```python
def run_llm(prompt: str, model: str = "llama3:8b"):  # Cambiar aquÃ­
```

### AÃ±adir nuevo cliente
1. Crea `data/clientes/mi_cliente.json`
2. Usa el formato de `everest_cocktails.json` como plantilla

### Personalizar prompts
Edita los archivos en `prompts/`:
- `estrategia.md` - LÃ³gica de generaciÃ³n de estrategias
- `contexto.md` - AdaptaciÃ³n al cliente
- `critico.md` - RevisiÃ³n y pulido final

## â— SoluciÃ³n de Problemas

### Ollama no responde
```bash
# Verificar que Ollama estÃ¡ corriendo
ollama list

# Reiniciar Ollama si es necesario
ollama serve
```

### Error de importaciÃ³n
```bash
# Reinstalar dependencias
pip install -r requirements.txt --upgrade
```

### Puerto ocupado
```bash
# Cambiar puerto en run_app.py o ejecutar:
streamlit run main.py --server.port 8502
```

## ğŸ”§ Desarrollo

### Estructura de archivos importante
```
chatbot_multiagentico_viara/
â”œâ”€â”€ main.py                    # ğŸ–¥ï¸ Frontend Streamlit
â”œâ”€â”€ orchestrator_parallel.py   # ğŸ¤– Backend multiagente
â”œâ”€â”€ run_app.py                 # ğŸš€ Script de inicio
â”œâ”€â”€ agents/                    # ğŸ§  LÃ³gica de agentes
â”œâ”€â”€ prompts/                   # ğŸ“ Templates editables
â”œâ”€â”€ data/clientes/             # ğŸ‘¥ Configuraciones de cliente
â””â”€â”€ utils/                     # ğŸ› ï¸ Funciones auxiliares
```

### Comandos Ãºtiles
```bash
# Limpiar cache de Streamlit
streamlit cache clear

# Ver logs detallados
streamlit run main.py --logger.level debug

# Ejecutar en modo de desarrollo
streamlit run main.py --server.runOnSave true
```

Â¡Ya tienes VIARA listo para generar contenido de marketing digital! ğŸ‰